{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build pipeline with sweep node\n",
        "\n",
        "**Requirements** - In order to benefit from this tutorial, you will need:\n",
        "- A basic understanding of Machine Learning\n",
        "- An Azure account with an active subscription - [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
        "- An Azure ML workspace with computer cluster - [Configure workspace](../../configuration.ipynb)\n",
        "- A python environment\n",
        "- Installed Azure Machine Learning Python SDK v2 - [install instructions](../../../README.md) - check the getting started section\n",
        "\n",
        "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
        "- Connect to your AML workspace from the Python SDK\n",
        "- Create sweep node with `sweep()`\n",
        "- Create `Pipeline` with sweep node\n",
        "\n",
        "**Motivations** - This notebook explains how to create a sweep node by using `sweep()` and use it in a pipeline. A sweep node can be used to enable hyperparameter tuning on a specified compute (either local or on the cloud) for a specific command component. You can define a `search_space` and an `objective` to search for the target output.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Connect to Azure Machine Learning Workspace\n",
        "\n",
        "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
        "\n",
        "## 1.1 Import the required libraries"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "from azure.ai.ml import MLClient, Input\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import load_component\n",
        "from azure.ai.ml.sweep import (\n",
        "    Choice,\n",
        "    Uniform,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1710926160131
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Configure credential\n",
        "\n",
        "We are using `DefaultAzureCredential` to get access to workspace. \n",
        "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
        "\n",
        "Reference for more available credentials if it does not work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1710926160252
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Get a handle to the workspace\n",
        "\n",
        "We use config file to connect to a workspace. The Azure ML workspace should be configured with computer cluster. [Check this notebook for configure a workspace](../../configuration.ipynb)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)\n",
        "\n",
        "# Retrieve an already attached Azure Machine Learning Compute.\n",
        "cluster_name = \"ej-cluster2\"\n",
        "print(ml_client.compute.get(cluster_name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "enable_node_public_ip: true\nid: /subscriptions/876b91eb-54d6-4433-af3b-5c9914d5ccea/resourceGroups/ej_vision_playground/providers/Microsoft.MachineLearningServices/workspaces/ej-workshop-workspace/computes/ej-cluster2\nidle_time_before_scale_down: 120\nlocation: westeurope\nmax_instances: 6\nmin_instances: 1\nname: ej-cluster2\nprovisioning_state: Succeeded\nsize: Standard_NC6s_v3\nssh_public_access_enabled: false\ntier: low_priority\ntype: amlcompute\n\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1710926161163
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Pipeline job with hyperparameter sweep\n",
        "\n",
        "## 2.1 Build pipeline\n",
        "In pipeline definition, we define `search_space` for hyperparameter sweep in inputs of `train_model` and call `train_model.sweep()` to create a sweep node based on `train_model` with specific run settings. Run settings includes:\n",
        "- objective_primary_metric \n",
        "- objective_goal\n",
        "- sampling_algorithm\n",
        "- limits\n",
        "- early_termination_policy\n",
        "- compute\n",
        "\n",
        "Please check section **3. Run a sweep on this command** in [Run hyperparameter sweep on a Command or CommandComponent](../../single-step/lightgbm/iris/lightgbm-iris-sweep.ipynb) for detailed explanation for the above concepts and settings.\n",
        "\n",
        "Noted that the **primary metric** of sweep objective must be **LOGGED** in the definition of `train_model`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_component_func = load_component(source=\"./train.yml\")\n",
        "score_component_func = load_component(source=\"./predict.yml\")\n",
        "\n",
        "# define a pipeline\n",
        "@pipeline()\n",
        "def pipeline_with_hyperparameter_sweep():\n",
        "    \"\"\"Tune hyperparameters using sample components.\"\"\"\n",
        "    train_model = train_component_func(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"wasbs://datasets@azuremlexamples.blob.core.windows.net/iris.csv\",\n",
        "        ),\n",
        "        c_value=Uniform(min_value=0.5, max_value=0.9),\n",
        "        kernel=Choice([\"rbf\", \"linear\", \"poly\"]),\n",
        "        coef0=Uniform(min_value=0.1, max_value=1),\n",
        "        degree=3,\n",
        "        gamma=\"scale\",\n",
        "        shrinking=False,\n",
        "        probability=False,\n",
        "        tol=0.001,\n",
        "        cache_size=1024,\n",
        "        verbose=False,\n",
        "        max_iter=-1,\n",
        "        decision_function_shape=\"ovr\",\n",
        "        break_ties=False,\n",
        "        random_state=42,\n",
        "    )\n",
        "    sweep_step = train_model.sweep(\n",
        "        primary_metric=\"training_f1_score\",\n",
        "        goal=\"minimize\",\n",
        "        sampling_algorithm=\"random\",\n",
        "        compute=\"ej-cluster2\",\n",
        "    )\n",
        "    sweep_step.set_limits(max_total_trials=20, max_concurrent_trials=10, timeout=7200)\n",
        "\n",
        "    score_data = score_component_func(\n",
        "        model=sweep_step.outputs.model_output, test_data=sweep_step.outputs.test_data\n",
        "    )\n",
        "\n",
        "\n",
        "pipeline_job = pipeline_with_hyperparameter_sweep()\n",
        "\n",
        "# set pipeline level compute\n",
        "pipeline_job.settings.default_compute = \"ej-cluster2\""
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "name": "enable-sweep",
        "gather": {
          "logged": 1710926161749
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Submit pipeline job"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# submit job to workspace\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=\"hyper-param-sweep\"\n",
        ")\n",
        "pipeline_job"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "{\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Operation returned an invalid status 'Not found compute with name cpu-cluster'\",\n      \"path\": \"jobs.sweep_step.compute\",\n      \"value\": \"azureml:cpu-cluster\"\n    }\n  ]\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:538\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_validation:\n\u001b[0;32m--> 538\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_failure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Create all dependent resources\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:472\u001b[0m, in \u001b[0;36mJobOperations._validate\u001b[0;34m(self, job, raise_on_failure, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m validation_result\u001b[38;5;241m.\u001b[39mresolve_location_for_diagnostics(job\u001b[38;5;241m.\u001b[39m_source_path)\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidation_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_failure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mErrorTarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPELINE\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/entities/_validation.py:277\u001b[0m, in \u001b[0;36mMutableValidationResult.try_raise\u001b[0;34m(self, error_target, error_category, raise_error, schema, additional_message, raise_mashmallow_error)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(message)\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    278\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m    279\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation failed on the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_messages),\n\u001b[1;32m    280\u001b[0m         target\u001b[38;5;241m=\u001b[39merror_target,\n\u001b[1;32m    281\u001b[0m         error_category\u001b[38;5;241m=\u001b[39merror_category,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[0;31mValidationException\u001b[0m: {\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Operation returned an invalid status 'Not found compute with name cpu-cluster'\",\n      \"path\": \"jobs.sweep_step.compute\",\n      \"value\": \"azureml:cpu-cluster\"\n    }\n  ]\n}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# submit job to workspace\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pipeline_job \u001b[38;5;241m=\u001b[39m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhyper-param-sweep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pipeline_job\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:607\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarshmallow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m SchemaValidationError\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n\u001b[0;32m--> 607\u001b[0m     \u001b[43mlog_and_raise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_exception_helper.py:295\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[0;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(formatted_error)\n",
            "\u001b[0;31mException\u001b[0m: {\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Operation returned an invalid status 'Not found compute with name cpu-cluster'\",\n      \"path\": \"jobs.sweep_step.compute\",\n      \"value\": \"azureml:cpu-cluster\"\n    }\n  ]\n}"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1710926162541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait until the job completes\n",
        "ml_client.jobs.stream(pipeline_job.name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710926162601
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps\n",
        "You can see further examples of running a pipeline job [here](../)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "interpreter": {
      "hash": "3e9e0e270b75c5e6da2e22113ba4f77b864d68f95da6601809c29e46c73ae6bb"
    },
    "categories": [
      "SDK v2",
      "sdk",
      "python",
      "jobs",
      "pipelines"
    ],
    "description": {
      "description": "Use sweep (hyperdrive) in pipeline to train mnist model using tensorflow"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}